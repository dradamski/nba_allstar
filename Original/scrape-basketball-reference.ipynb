{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping of www.basketball-reference.com\n",
    "\n",
    "During this portion of the project, I was focused on collecting the data needed for my project. I needed to scrape data from www.basketball-reference.com which I was able to do using BeautifulSoup, pandas, and urllib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first question I had to answer before starting any of this is what players should I consider in my analysis? I decided to use Hall of Fame Probability as a preliminary deciding factor. Created by the people at Basketball Reference, Hall of Fame Probability measures exactly what the name not-so-subtly suggests: a player's probability of making it into the Basketball Hall of Fame. \n",
    "\n",
    "Given the nature of my problem (predicting a player's performance dropoff before it happens), it seemed most logical to look at players who performed at a high level. \n",
    "\n",
    "I scraped the all-time leaders in this metric as well as the active leaders. There was some overlap in the players, so I ended up with 310 unique players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Basketball Reference to get league leaders in win shares for each season\n",
    "#specify the url\n",
    "site = \"https://www.basketball-reference.com/leaders/hof_prob.html\"\n",
    "#Query the website and return the html to the variable 'page'\n",
    "page = urllib.request.urlopen(site)\n",
    "#Parse the html in the 'page' variable and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(page, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save two Hall of Fame Probability leader tables (all time and active)\n",
    "alltime_table, active_table = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list tuples of players and href \n",
    "alltime_list = []\n",
    "active_list = []\n",
    "for line in alltime_table('td'):\n",
    "    try:\n",
    "        alltime_list.append((str(line.a.string), str(line.a.get('href'))))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for line in active_table('td'):\n",
    "    try:\n",
    "        active_list.append((str(line.a.string), str(line.a.get('href'))))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`alltime_list` and `active_list` are lists of tuples containing the player's name and the path to access their season statistics. I have printed the length and top 5 entries to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250,\n",
       " [('Kareem Abdul-Jabbar', '/players/a/abdulka01.html'),\n",
       "  ('Michael Jordan', '/players/j/jordami01.html'),\n",
       "  ('Bill Russell', '/players/r/russebi01.html'),\n",
       "  ('Kobe Bryant', '/players/b/bryanko01.html'),\n",
       "  ('Wilt Chamberlain', '/players/c/chambwi01.html')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alltime_list), alltime_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " [('LeBron James', '/players/j/jamesle01.html'),\n",
       "  ('Dwyane Wade', '/players/w/wadedw01.html'),\n",
       "  ('Dirk Nowitzki', '/players/n/nowitdi01.html'),\n",
       "  ('Kevin Durant', '/players/d/duranke01.html'),\n",
       "  ('Chris Paul', '/players/p/paulch01.html')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(active_list), active_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I needed to combine the two lists and remove players on both lists. I did this using set functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "[('Jodie Meeks', '/players/m/meeksjo01.html'), ('Mike Conley', '/players/c/conlemi01.html'), ('Brook Lopez', '/players/l/lopezbr01.html'), ('Rudy Gobert', '/players/g/goberru01.html'), ('Ricky Rubio', '/players/r/rubiori01.html'), ('Jae Crowder', '/players/c/crowdja01.html'), ('Harrison Barnes', '/players/b/barneha02.html'), ('Tony Allen', '/players/a/allento01.html'), ('Jamal Crawford', '/players/c/crawfja01.html'), ('Shaun Livingston', '/players/l/livinsh01.html')]\n"
     ]
    }
   ],
   "source": [
    "# Create list of players on active_list but not alltime_list\n",
    "# and add to alltime_list\n",
    "active_list = list(set(active_list).difference(set(alltime_list)))\n",
    "alltime_list += active_list\n",
    "# Print new list length and last 10 players of list\n",
    "print(len(alltime_list))\n",
    "print(alltime_list[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Season Statistics\n",
    "This for loop gets the season by season stats for each player in the alltime_list. First it turns the player page html into a Beautiful Soup object to make the stats table. I also pull the player's height from the top of the page, and convert it from a string 'x-xx' to inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  seasons of  Kareem Abdul-Jabbar added\n",
      "Michael Jordan Did Not Play (retired)\n",
      "Michael Jordan Did Not Play (retired)\n",
      "Michael Jordan Did Not Play (retired)\n",
      "17  seasons of  Michael Jordan added\n",
      "13  seasons of  Bill Russell added\n",
      "20  seasons of  Kobe Bryant added\n",
      "16  seasons of  Wilt Chamberlain added\n",
      "16  seasons of  LeBron James added\n",
      "19  seasons of  Tim Duncan added\n",
      "21  seasons of  Shaquille O'Neal added\n",
      "16  seasons of  John Havlicek added\n",
      "14  seasons of  Oscar Robertson added\n"
     ]
    }
   ],
   "source": [
    "all_seasons = [] \n",
    "for player in alltime_list[:10]:\n",
    "    reference_site = 'https://www.basketball-reference.com' + player[1]\n",
    "    page = urllib.request.urlopen(reference_site)\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    per_game_table = soup.table\n",
    "    \n",
    "    height = str(soup.find_all('div', {'id':'info'})[0].find_all('span', {'itemprop':'height'})[0].string)\n",
    "    height = height.split('-')\n",
    "    height = int(height[0])*12 + int(height[1])\n",
    "    \n",
    "    # This section gets stats values for a single season and \n",
    "    # makes a single list\n",
    "    values = []\n",
    "    length = 0\n",
    "    for row in (per_game_table('tr')):\n",
    "        for num, column in enumerate(row):\n",
    "            # Players from different decades have different\n",
    "            # available stats, but PTS is always the last column\n",
    "            if column.string == 'PTS':\n",
    "                length = int((num+1) / 2)\n",
    "            if column != '\\n':\n",
    "                values.append(str(column.string))\n",
    "    categories = values[:length]\n",
    "    # Ignores category names\n",
    "    values = values[length:]\n",
    "\n",
    "    # Create list of individual season stats lists\n",
    "    player_career = [['Player', 'href', 'Height'] + categories]\n",
    "    season = [player[0], player[1], height]\n",
    "    for value in values:\n",
    "        if value.startswith('Did'):\n",
    "            # Find players who took time off mid-career\n",
    "            print(player[0], value)\n",
    "        season.append(str(value))\n",
    "        #added and (season[3] != None)\n",
    "        if (len(season) == length+3) and (season[4] != 'None'):\n",
    "            player_career.append(season)\n",
    "            season = [player[0], player[1], height]\n",
    "        # Player must have played at least 12 seasons\n",
    "    #if (len(player_career) > 12):# and (len(player_career[0]) == 33):\n",
    "    all_seasons.append(player_career)\n",
    "    print(str((len(player_career)-1)), ' seasons of ', player[0], 'added')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to DataFrame and Exporting to .csv\n",
    "The scraped data was scraped into a single list which is not useful to me, so I need to convert it to a pandas DataFrame before I exported it to a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas DataFrame of all data\n",
    "category_list= ['Player', 'href', 'Height', 'Season', 'Age', 'Tm', 'Lg', \n",
    "                'Pos', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', \n",
    "                '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', \n",
    "                'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kareem Abdul-Jabbar added\n",
      "Michael Jordan added\n",
      "Bill Russell added\n",
      "Kobe Bryant added\n",
      "Wilt Chamberlain added\n",
      "LeBron James added\n",
      "Tim Duncan added\n",
      "Shaquille O'Neal added\n",
      "John Havlicek added\n",
      "Oscar Robertson added\n"
     ]
    }
   ],
   "source": [
    "# Merge DataFrames and export to csv\n",
    "df_list = []\n",
    "season_df_list = []\n",
    "master_df = pd.DataFrame(columns=category_list)\n",
    "for career in all_seasons:\n",
    "    labels=career[0]\n",
    "    for season in career[1:]:\n",
    "        season_df = pd.DataFrame(data=season, index=labels)\n",
    "        season_df_list.append(season_df.transpose())\n",
    "    print(career[1][0] + ' added')\n",
    "career_df = pd.concat(season_df_list, ignore_index=True, sort=True)\n",
    "    \n",
    "\n",
    "career_df.to_csv('all-stats-sample.csv', columns = category_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
